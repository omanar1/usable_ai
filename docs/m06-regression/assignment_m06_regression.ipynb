{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6 - Regression\n",
    "In this guide, we will be exploring using regression as an intro to artificial intelligence. \n",
    "For this week's assignment, we will be exploring linear regression. We'll be using the data from our soccer database from assignment 4.\n",
    "\n",
    "### Instructions\n",
    "1. Follow the instructions on how to setup your Python and Jupyter (or VSCode) environment and cloning or downloading our repository. Instructions can be found in the class notes.\n",
    "2. Import soccer database using pandas.\n",
    "3. Load the values from the attributes `gk_reflexes` and `gk_handling` from table `Player_Attributes`.\n",
    "4. Use `gk_reflexes` (as x) and `gk_handling` (as y) as your data.\n",
    "5. Drop the missing values from these two columns.\n",
    "6. Scale the dataset using a standard scaler.\n",
    "7. Split the data into training and testing in a 0.3 ratio (70% training, 30% testing).\n",
    "8. Apply Linear Regression, Cross-Validation (with 5 splits), Ridge Regularization, and Lasso Regularizations and print the co-relation result of each technique using `r2_score`. All of the functions for this last step are located in sklearn.\n",
    "9. Answer the questions in the notebook through code.\n",
    "10. Run the notebook and make sure everything works.\n",
    "11. Export the notebook as HTML or PDF.\n",
    "12. Submit the notebook through Canvas.\n",
    "\n",
    "Remember to fill the missing pieces of code in the provided notebook.\n",
    "\n",
    "### Dataset Overview\n",
    "The dataset covers information about soccer players in sqlite format. This file is located in the `Datasets` directory of this repository. The file is called `fifa_soccer_dataset.sqlite.gz`. **This is the same file from the previous homework (assignment 4).**\n",
    "\n",
    "If you haven't decompressed the file, you may need to follow the instructions below to decompress it.\n",
    "\n",
    "**IMPORTANT** The database is compressed and needs to be decompressed before use. You can do this by running the following command in your terminal on Linux or MacOS:\n",
    "\n",
    "```bash\n",
    "gunzip Datasets/fifa_soccer_dataset.sqlite.gz\n",
    "```\n",
    "\n",
    "If you are using Windows, you can use the following command in your powershell:\n",
    "\n",
    "```powershell\n",
    "$sourceFile = \"$PWD\\Datasets\\fifa_soccer_dataset.sqlite.gz\"\n",
    "$destinationFile = \"$PWD\\Datasets\\fifa_soccer_dataset.sqlite\"\n",
    "\n",
    "$inputStream = [System.IO.File]::OpenRead($sourceFile)\n",
    "$outputStream = [System.IO.File]::Create($destinationFile)\n",
    "$gzipStream = New-Object System.IO.Compression.GzipStream($inputStream, [System.IO.Compression.CompressionMode]::Decompress)\n",
    "$gzipStream.CopyTo($outputStream)\n",
    "\n",
    "$gzipStream.Close()\n",
    "$outputStream.Close()\n",
    "$inputStream.Close()\n",
    "```\n",
    "\n",
    "Alternatively, you can extract the file using the GUI of your operating system.\n",
    "\n",
    "\n",
    "### Submission Guidelines\n",
    "\n",
    "- Submit your completed notebook as a HTML export, or a PDF file.\n",
    "\n",
    "To export to HTML, if you are on Jupyter, select `File` > `Export Notebook As` > `HTML`.\n",
    "\n",
    "If you are on VSCode, you can use the `Jupyter: Export to HTML` command.\n",
    " - Open the command palette (Ctrl+Shift+P or Cmd+Shift+P on Mac).\n",
    "     - Search for `Jupyter: Export to HTML`.\n",
    "     - Save the HTML file to your computer and submit it via Canvas.\n",
    "\n",
    "---\n",
    "\n",
    "To begin, we'll need quite a few imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9589f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the soccer data to run regressions. In the cell below, connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Code Here\n",
    "dataset_path = \"../../Datasets/fifa_soccer_dataset.sqlite\" # Fix your path accordingly\n",
    "\n",
    "conn = sqlite3.connect(dataset_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, let's write a query to grab all of the entries from the `Player_Attributes` table, and print the first 5 rows below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa41ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_attr_df = pd.read_sql(\"Your Query Here\", _) # Input Code Here\n",
    "\n",
    "# Display the first 5 rows of the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to play with two fields today, the `gk_handling` field as the dependent feature and the `gk_reflexes` field as the independent feature. Let's drop some missing values from these two columns as well. They represent the goalkeeping handling and reflexes of a player respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bde5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Code Here - Drop null values from the mentioned columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb5828f",
   "metadata": {},
   "source": [
    "Let's store those columns in their own variables for easy reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = player_attr_df[['Column Here']].values # Input Code Here\n",
    "y = player_attr_df[['Column Here']].values # Input Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preform and evaluate our linear regression, we need to split our data into test and training batches. We can do this by using the `train_test_split()` function. In the cell below, use this function and pass it `x` and `y` as the data for it to split. The final parameter `test_size` indicates how big the test batch should be, in this case 30% of the initial dataset inputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84575fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = _(_, _, test_size = 0.3) #Input Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now preform the fitting. Let's call the `fit()` function on our `lm` variable, passing the `X_train` and `Y_train` data as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b476fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm._(_, _) # Input Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we can use the predict funtion to see how the model preforms against our test data set. Call the `predict()` function on `lm` and pass `X_test` as our input parameter. We'll then see the r2 score to see how correlated these values are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = lm._(_) # Input Code Here\n",
    "rsquared = r2_score(_, _)\n",
    "print(\"R2 Score: \" + str(rsquared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are pretty correlated! We can also use the `StandarScalar()` to transform our values before fitting our model. In the cell below, call the `StandardScalar()` function and pass `x` and `y` to the `fit_transform()` functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54856d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = _() # Input Code Here\n",
    "\n",
    "x_scaled = sc.fit_transform(_) # Input Code Here\n",
    "y_scaled = sc.fit_transform(_) # Input Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the model again as we did before. We'll need to split the training and test batches again, then run a new `fit()`. Once fitted, we can again use `predict()` and run a r2 score again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd203263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Code Here to split the scaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d855b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Code Here to create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = lm._(X_test) # Input Code Here\n",
    "# Input Code Here - Grab the R2 Score like we did above\n",
    "print(\"R2 Score: \" + str(rsquared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea4980",
   "metadata": {},
   "source": [
    "Implementing various models - LinearRegression(), Ridge(), Lasso() along with K-Fold CrossValidation with 5 splits.\n",
    "Use the unscaled data for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc928fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Linear regression, ridge regularization, lasso regularization with cross validation\n",
    "\n",
    "# Define models\n",
    "model_lr = _\n",
    "model_ridge = _\n",
    "model_lasso = _\n",
    "\n",
    "# Cross validation\n",
    "kf = KFold(n_splits = _)\n",
    "list_r2_score = [] # to keep the r2 score\n",
    "# Split the train set:\n",
    "for train_index, test_index in kf.split(_):\n",
    "    X_train, X_test = _[train_index], _[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    k_fold_r2 = []\n",
    "    for model in [_, _, _]:\n",
    "        model._(X_train, y_train)\n",
    "        pred = model.predict(_)\n",
    "        k_fold_r2.append(r2_score(_, _))\n",
    "    list_r2_score.append(k_fold_r2)\n",
    "    \n",
    "# Show the result - Add Mean and Standard Deviation of the R2-scores\n",
    "list_r2_score.append(list(np.mean(list_r2_score, axis = _)))\n",
    "list_r2_score.append(list(np.std(list_r2_score[:-1], axis = _)))\n",
    "result_r2 = pd.DataFrame(list_r2_score)\n",
    "result_r2.columns = ['Linear Regression', 'Ridge', 'Lasso']\n",
    "result_r2.index = ['k1', 'k2', 'k3', 'k4', 'k5', 'average', 'std']\n",
    "\n",
    "print('The result of r2 scores for k=5 cross validation')\n",
    "display(result_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's basic linear regression with python. Please turn in this notebook completed with your outputs displayed in html or pdf formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1692b28",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
