{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8pWGEwGb-Ol"
      },
      "source": [
        "# Homework 10 - Sentiment Analysis with TF-IDF Vectorization\n",
        "In this assignment, we will apply NLP concepts from lecture and use TF-IDF Vectorization. We will need to use the sentiment dataset linked to from the canvas assignment page. Make sure to have this downloaded for using this guide. As always, we'll first need a few libraries for this assignment.\n",
        "\n",
        "Complete the missing parts in this guide.\n",
        "\n",
        "### Step 1: Load Data\n",
        "You can load the data from the provided TSV file using `pandas`.\n",
        "\n",
        "### Step 2: Preprocess\n",
        " - Clean the data by removing stop-words, punctuations, emoticons etc..\n",
        "\n",
        "### Step 3: Train and test a model to predict the sentiment of each sentence\n",
        " - Train and test the model using TfidfVectorizer, Pipeline, Logistic regression with this data.\n",
        " - Print the best_params_, best_score_, score.\n",
        "\n",
        "### Step 4: Repeat for all the datasets\n",
        " - 'amazon_cells_labelled.tsv'\n",
        " - 'yelp_labelled.tsv'\n",
        " - 'imdb_labelled.tsv'\n",
        "\n",
        "## Dataset Overview\n",
        "The dataset obtained originally from https://archive.ics.uci.edu/dataset/331/sentiment+labelled+sentences contains sentences labeled with sentiment. Each sentence is associated with a sentiment label (positive or negative). The dataset is split into three parts, each containing sentences from different sources: Amazon, Yelp, and IMDb.\n",
        "Score is either 1 (for positive) or 0 (for negative)\t\n",
        "\n",
        "\n",
        "## Submission Guidelines\n",
        "\n",
        "- Submit your completed notebook as a HTML export, or a PDF file.\n",
        "\n",
        "To export to HTML, if you are on Jupyter, select `File` > `Export Notebook As` > `HTML`.\n",
        "\n",
        "If you are on VSCode, you can use the `Jupyter: Export to HTML` command.\n",
        " - Open the command palette (Ctrl+Shift+P or Cmd+Shift+P on Mac).\n",
        "     - Search for `Jupyter: Export to HTML`.\n",
        "     - Save the HTML file to your computer and submit it via Canvas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jtkHRGH4b-Om"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import re\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WhlJElyb-On"
      },
      "source": [
        "The datasets have two columns: `sentence` and `score`. The `sentence` column contains the text of the sentence, and the `score` column contains the sentiment label (1 for positive, 0 for negative)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PD_MYuPwb-On"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  score\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"../../Datasets/yelp_labelled.tsv\", sep=\"\\t\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-Iwy5owb-On"
      },
      "source": [
        "Great! Now we need to clean up the dataframe by removing non words like stop-test, and punctuation. Fill in the code for the `remove_punctuation()` and `remove_stopwords()` functions as described in lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXxrl3JBdPqE"
      },
      "source": [
        "Note: In addition to the 'remove_punctuation' and 'remove_stopwords', you can also try to check for lower case and upper case and convert to lower case accordingly. You can also tokenize the text, stemming the tokens and then join the stemmed tokens back into a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPvRCNteb-On"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Your Code Here\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    # Your Code Here\n",
        "\n",
        "df['sentence'] = df['sentence'].apply(remove_punctuation).apply(remove_stopwords)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8xSAEhUeEo_"
      },
      "source": [
        "Split the cleaned dataset using train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zOuVnZ6eIkn"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsoGZjdWfNkn"
      },
      "source": [
        "Define a pipeline with the asked models(tfifd and Logistic Regression) in our case"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOxpyBlsb-On"
      },
      "source": [
        "Next we can call the `TfidfVectorizer()` function, passing it 'english' as a parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfl8juwZfajH"
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline((), () ) # Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhBHZF04fkY6"
      },
      "source": [
        "Next, you can define a parameter grid for finding the best hyperparameters, then use GridsearchCV and pass the pipeline to find the best parameters and then fit the model using the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLkCVh0MfqnU"
      },
      "outputs": [],
      "source": [
        "param_grid = { } # Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFlLNXqdgMal"
      },
      "outputs": [],
      "source": [
        "# Your code for GridsearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3caY_l6MgOQ8"
      },
      "outputs": [],
      "source": [
        "# Your code to fit the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0M7MmXYglRH"
      },
      "source": [
        "Write a code to print the best_params_, best_score_, score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "75Yw5okZgs2h"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Now repeat the above steps for the remaining datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
