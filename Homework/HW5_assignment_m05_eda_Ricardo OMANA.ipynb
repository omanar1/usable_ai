{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Exploratory Data Analysis (EDA)\n",
    "In this assignment, you are going to perform exploratory data analysis (EDA) on a small dataset of your choice. You can choose any dataset you like, but you are encouraged to pick a dataset that you are interested in. You can use the datasets you have used in the previous assignments or you can choose a new dataset. If you don't have a dataset in mind, you can choose one from the datasets in the `Datasets` folder of the course repository.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Follow the instructions on how to setup your Python and Jupyter (or VSCode) environment and cloning or downloading our repository. Instructions can be found in the class notes:\n",
    "   https://filipinascimento.github.io/usable_ai/m00-setup/class\n",
    "2. Ensure that you have Python and Jupyter Notebook working. (You can also try using Google Colab. This is not the preferred method for this homework, but it is an option)\n",
    "3. Load the dataset of your choice into a Pandas dataframe\n",
    "4. Perform exploratory data analysis (EDA) on the dataset. Your analysis should include the following:\n",
    "    - Summary statistics of the dataset\n",
    "    - Data cleaning and preprocessing\n",
    "    - Data visualization (e.g., histograms, scatterplots, etc.)\n",
    "    - You should write a brief summary of the insights and conclusions you have drawn from your analysis.\n",
    "    You can use the [exploratory_data_analysis.ipynb](notebook) as a reference.\n",
    "5. **Important**: Create both code and markdown cells in your notebook to document your analysis.\n",
    "6. Submit your completed notebook as a HTML export, or a PDF file.\n",
    "\n",
    "### Submission Guidelines\n",
    "\n",
    "- Submit your completed notebook as a HTML export, or a PDF file.\n",
    "\n",
    "To export to HTML, if you are on Jupyter, select `File` > `Export Notebook As` > `HTML`.\n",
    "\n",
    "If you are on VSCode, you can use the `Jupyter: Export to HTML` command.\n",
    " - Open the command palette (Ctrl+Shift+P or Cmd+Shift+P on Mac).\n",
    "    - Search for `Jupyter: Export to HTML`.\n",
    "    - Save the HTML file to your computer and submit it via Canvas.\n",
    "\n",
    "---\n",
    "\n",
    "> \n",
    "> **Using Generative AI Responsibly**\n",
    ">\n",
    "> You're welcome to use Generative AI to assist your learning, but focus on understanding the concepts rather than just solving the assignment. For example, instead of copying and pasting the question into the model, ask it to explain the concept in the question. Try asking: `How can I open a file in Python? Can you give me examples?` or `What functions and methods can I use to extract the words of a text file? Can you explain how they work with some examples?`\n",
    ">\n",
    "> This way, you will learn how the solution works while building your skills. Remember to give context to the generative AI, so it can better assist you. Talk to the instructor and AIs if you have any questions or need insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your cells below this one. Hint: start by imporint the necessary libraries and loading your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## SOURCE DATASET ##\n",
    "\n",
    "Took data from **FormulaAI Hackathon 2022** for the first theme about creating an accurate weather prediction model for the F1 2021 video game.\n",
    "The data is given in two formats CSV and JSON. I took the CSV as it is faster to process in my PC (size 716 MB).\n",
    "\n",
    "``[1]`` https://www.kaggle.com/datasets/oracledevrel/formulaaihackathon2022\n",
    "\n",
    "``[2]`` https://github.com/oracle-devrel/formula-ai-2022-hackathon\n",
    "\n",
    "``[3]`` https://github.com/oracle-devrel/formula-ai-2022-hackathon/blob/main/challenges/challenge1.md\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset of your choice into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules needed - following \"Module 05 - Exploratory Data Analysis\"\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Local directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation about selection of the input file format ###\n",
    "\n",
    "Initially, I selected the .csv but it flatten the data that was included as objects under columns \"\n",
    "It means that by using .csv, I ended skyrocketing the number of entries (or rows).\n",
    "\n",
    "The JSON took more time to load but I do not end up with the problem of artifitialy create duplicates.\n",
    "So I decided to select the JSON file.\n",
    "\n",
    "```log .CSV file\n",
    "RangeIndex: 3572328 entries, 0 to 3572327\n",
    "Data columns (total 59 columns)\n",
    "```\n",
    "\n",
    "```log .JSON file\n",
    "RangeIndex: 339692 entries, 0 to 339691\n",
    "Data columns (total 41 columns)\n",
    "```\n",
    "**What is happening between .CSV vs. .JSON**\n",
    "\n",
    "Im this case, it is not a problem as it is only one instance for the different components of the object, so it is translated as additional columns.\n",
    "\n",
    "|JSON | CSV (multiple columns) |\n",
    "|---|---|\n",
    "|m_header (object)<br/>{'m_packet_format': 2021, <br/>'m_game_major_version': 1, <br/>'m_game_minor_version': 14, <br/>'m_packet_version': 1, <br/>'m_packet_id': 1, <br/>'m_session_uid': 13002103581294142936, <br/>'m_session_time': 2803.836, <br/>'m_frame_identifier': 82458, <br/>'m_player_car_index': 0, <br/>'m_secondary_player_car_index': 255}|M_PACKET_FORMAT<br/>M_GAME_MAJOR_VERSION<br/>M_GAME_MINOR_VERSION<br/>M_PACKET_VERSION<br/>M_PACKET_ID<br/>...<br/>M_SECONDARY_PLAYER_CAR_INDEX|\n",
    "\n",
    "But in this case then the duplication start to appeared so it is possible get rid of the object and end up with additional columns:\n",
    "\n",
    "|JSON |\n",
    "|---|\n",
    "m_marshal_zones (object)<br/>[{'m_zone_start': 0.088, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.167, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.23800000000000002, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.298, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.353, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.41200000000000003, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.45, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.495, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.54, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.62, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.6900000000000001, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.726, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.789, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.8310000000000001, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.925, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0.997, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, <br/>{'m_zone_start': 0, 'm_zone_flag': 0}]|\n",
    "\n",
    "The above applies to the other 3 objects: ```m_marshal_zones```, ```gamehost```, ```m_weather_forecast_samples```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting info about objects in JSON\n",
    "\n",
    "pd.set_option('max_colwidth', 50) # Set the maximum width of column to display all content so it is easy to observe the objects\n",
    "# print(df_weather['m_weather_forecast_samples'].head(1))\n",
    "\n",
    "# {'m_packet_format': 2021, 'm_game_major_version': 1, 'm_game_minor_version': 14, 'm_packet_version': 1, 'm_packet_id': 1, 'm_session_uid': 13002103581294142936, 'm_session_time': 2803.836, 'm_frame_identifier': 82458, 'm_player_car_index': 0, 'm_secondary_player_car_index': 255}\n",
    "# Name: m_header, dtype: object\n",
    "\n",
    "# [{'m_zone_start': 0.088, 'm_zone_flag': 0}, {'m_zone_start': 0.167, 'm_zone_flag': 0}, {'m_zone_start': 0.23800000000000002, 'm_zone_flag': 0}, {'m_zone_start': 0.298, 'm_zone_flag': 0}, {'m_zone_start': 0.353, 'm_zone_flag': 0}, {'m_zone_start': 0.41200000000000003, 'm_zone_flag': 0}, {'m_zone_start': 0.45, 'm_zone_flag': 0}, {'m_zone_start': 0.495, 'm_zone_flag': 0}, {'m_zone_start': 0.54, 'm_zone_flag': 0}, {'m_zone_start': 0.62, 'm_zone_flag': 0}, {'m_zone_start': 0.6900000000000001, 'm_zone_flag': 0}, {'m_zone_start': 0.726, 'm_zone_flag': 0}, {'m_zone_start': 0.789, 'm_zone_flag': 0}, {'m_zone_start': 0.8310000000000001, 'm_zone_flag': 0}, {'m_zone_start': 0.925, 'm_zone_flag': 0}, {'m_zone_start': 0.997, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}]\n",
    "# Name: m_marshal_zones, dtype: object\n",
    "\n",
    "# f1digest\n",
    "# Name: gamehost, dtype: object\n",
    "\n",
    "# [{'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_sessio...\n",
    "# Name: m_weather_forecast_samples, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Perform exploratory data analysis (EDA) on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_weather = pd.read_csv(\"../Datasets/weather.csv\")\n",
    "df_weather = pd.read_json(\"../Datasets/weather.json\")\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference of columns data types and adding definition per ```[2]```\n",
    "\n",
    "| Column | Non-Null Count | Type | Definition [2] |\n",
    "|---|---|---|---|\n",
    "|m_header                        |339692 non-null  |object        |Object: Header\n",
    "|m_braking_assist                |339692 non-null  |int64         |0 = off, 1 = low, 2 = medium, 3 = high\n",
    "|m_session_link_identifier       |339692 non-null  |int64         |Identifier for session - persists across save\n",
    "|m_pit_release_assist            |339692 non-null  |int64         |0 = off, 1 = on\n",
    "|timestamp                       |339692 non-null  |datetime64[ns]|timestamp for when the packet was received\n",
    "|m_marshal_zones                 |339692 non-null  |object        |Object: zone_start::Fraction (0..1) of way through the lap the marshal zone starts;<br/> zone_flag::-1 = invalid/unknown, 0 = none, 1 = green, 2 = blue, 3 = yellow, 4 = red\n",
    "|m_pit_stop_window_ideal_lap     |339692 non-null  |int64         |Ideal lap to pit on for current strategy (player)\n",
    "|m_track_temperature             |339692 non-null  |int64         |Track temp. in degrees celsius\n",
    "|m_track_length                  |339692 non-null  |int64         |Track length in metres\n",
    "|m_game_paused                   |339692 non-null  |int64         |Whether the game is paused\n",
    "|m_forecast_accuracy             |339692 non-null  |int64         |0 = Perfect, 1 = Approximate.\n",
    "|gamehost                        |316403 non-null  |object        |Unique identifier for the host that captured the data (not relevant) \n",
    "|m_air_temperature               |339692 non-null  |int64         |Air temp. in degrees celsius\n",
    "|m_num_weather_forecast_samples  |339692 non-null  |int64         |Object of weather forecast samples\n",
    "|m_sli_pro_native_support        |339692 non-null  |int64         |SLI Pro support, 0 = inactive, 1 = active\n",
    "|m_safety_car_status             |339692 non-null  |int64         |0 = no safety car, 1 = full, 2 = virtual, 3 = formation lap\n",
    "|m_track_id                      |339692 non-null  |int64         |-1 for unknown, 0-21 for tracks\n",
    "|m_ersassist                     |339692 non-null  |int64         |0 = off, 1 = on\n",
    "|m_formula                       |339692 non-null  |int64         |Formula, 0 = F1 Modern, 1 = F1 Classic, 2 = F2, 3 = F1 Generic\n",
    "|m_season_link_identifier        |339692 non-null  |int64         |Identifier for season - persists across saves\n",
    "|m_pit_assist                    |339692 non-null  |int64         |0 = off, 1 = on\n",
    "|m_gearbox_assist                |339692 non-null  |int64         |1 = manual, 2 = manual & suggested gear, 3 = auto\n",
    "|m_session_type                  |339692 non-null  |int64         |0 = unknown, 1 = P1, 2 = P2, 3 = P3, 4 = Short P, 5 = Q1, 6 = Q2, 7 = Q3, 8 = Short Q, <br/>9 = OSQ, 10 = R, 11 = R2, 12 = R3, 13 = Time Trial\n",
    "|m_spectator_car_index           |339692 non-null  |int64         |Index of the car being spectated\n",
    "|m_pit_stop_window_latest_lap    |339692 non-null  |int64         |Latest lap to pit on for current strategy (player)\n",
    "|m_weekend_link_identifier       |339692 non-null  |int64         |Identifier for weekend - persists across saves\n",
    "|m_dynamic_racing_line_type      |339692 non-null  |int64         |0 = 2D, 1 = 3D\n",
    "|m_session_time_left             |339692 non-null  |int64         |Time left in session in seconds\n",
    "|m_session_duration              |339692 non-null  |int64         |Session duration in seconds\n",
    "|m_pit_stop_rejoin_position      |339692 non-null  |int64         |Predicted position to rejoin at (player)\n",
    "|m_weather_forecast_samples      |339692 non-null  |object        |Object: weather forecast\n",
    "|m_weather                       |339692 non-null  |int64         |Weather - 0 = clear, 1 = light cloud, 2 = overcast, 3 = light rain, 4 = heavy rain, 5 = storm\n",
    "|m_ai_difficulty                 |339692 non-null  |int64         |AI Difficulty rating â€“ 0-110\n",
    "|m_pit_speed_limit               |339692 non-null  |int64         |Pit speed limit in kilometres per hour\n",
    "|m_network_game                  |339692 non-null  |int64         |0 = offline, 1 = online\n",
    "|m_total_laps                    |339692 non-null  |int64         |Total number of laps in this race\n",
    "|m_steering_assist               |339692 non-null  |int64         |0 = off, 1 = on\n",
    "|m_is_spectating                 |339692 non-null  |int64         |Whether the player is spectating\n",
    "|m_dynamic_racing_line           |339692 non-null  |int64         |0 = off, 1 = corners only, 2 = full\n",
    "|m_drsassist                     |339692 non-null  |int64         |0 = off, 1 = on\n",
    "|m_num_marshal_zones             |339692 non-null  |int64 \t\t |Number of marshal zones to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows x Cols\n",
    "df_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Summary statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice statistics of the data will not cover the objects that were identified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_weather.describe().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column with std dev == 0\n",
    "\n",
    "display(df_weather['m_sli_pro_native_support'].describe().transpose())\n",
    "display(df_weather['m_sli_pro_native_support'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column m_sli_pro_native_support becuase it is the same across the board\n",
    "# using inplace=True to modify the DataFrame instead of creating a copy\n",
    "df_weather.drop(columns=['m_sli_pro_native_support'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls in the dataset and see list those columns only\n",
    "display(df_weather.columns[df_weather.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['gamehost'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'gamehost' column as it is not relevant  \n",
    "df_weather.drop(columns=['gamehost'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the columns that are objetcs\n",
    "df_weather.select_dtypes(include=['object']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether to keep or drop the column m_header by flattening the object\n",
    "print(df_weather['m_header'].apply(type).value_counts())  # Check data types\n",
    "# lets expand the dictionary\n",
    "df_expanded = df_weather['m_header'].apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the stats of the expanded dataframe\n",
    "display(df_expanded.describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some with std dev zero, we can drop because they are the same across the board\n",
    "# But lets check the unique values in each column in df_expanded\n",
    "\n",
    "for col in df_expanded.columns:\n",
    "    unique_values = df_expanded[col].unique()\n",
    "    print(f\"Column: {col}\")\n",
    "    print(unique_values)\n",
    "    print(\"-\" * 40)  # Separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly there are some with a unique value so we can drop them\n",
    "# for simplicity will drop this column m_header\n",
    "df_weather.drop(columns=['m_header'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity will drop the other columns that are type object - big assumption that they are not needed\n",
    "# m_marshal_zones\tm_weather_forecast_samples\n",
    "df_weather.drop(columns=['m_marshal_zones', 'm_weather_forecast_samples'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check df_weather info again\n",
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that column \"timestamp\" is type datetime, so it will be better to have day, month, year\n",
    "df_weather['year'] = df_weather['timestamp'].dt.year\n",
    "df_weather['month'] = df_weather['timestamp'].dt.month\n",
    "df_weather['day'] = df_weather['timestamp'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_weather[['year','month','day']].describe().transpose())\n",
    "display(df_weather['year'].unique())\n",
    "display(df_weather['month'].unique())\n",
    "display(df_weather['day'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can drop year as it is not changing\n",
    "df_weather.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the duplicates rows in df_weather sort by timestamp\n",
    "# First lets analyze\n",
    "duplicates = df_weather.duplicated(keep=False)  # Mark all duplicates (including first occurrences)\n",
    "print('Summary of duplicated rows (including first case):')\n",
    "print(duplicates.groupby(duplicates).size())  # Count the occurrences of each duplicate status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets show one case of duplicate rows\n",
    "df_duplicate_records = df_weather[duplicates == True]\n",
    "\n",
    "# Get one duplicate case (first duplicate row)\n",
    "if not df_duplicate_records.empty:\n",
    "    first_duplicate = df_duplicate_records.iloc[0]  # Select first duplicate row\n",
    "    case = df_duplicate_records[df_duplicate_records.eq(first_duplicate).all(axis=1)]  # Get all rows identical to it\n",
    "    print(\"One case of duplicate rows:\")\n",
    "    display(case)\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drope duplicates in df_weather and keep the first occurence\n",
    "df_weather.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset after cleaning\n",
    "df_weather.info()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA CLEANING SUMMARY** ##\n",
    "-----------\n",
    "\n",
    "**CSV vs JSON**<br/>\n",
    "The data was available in both formats, started with CSV (faster to load), however, there were elemens that inflated the actual observations - no \"Tidy\" data.\n",
    "Therefore, I focus on the JSON as import format.\n",
    "Note: At the end of the notebook there is a section (**FOR REFERENCE: OLD Analysis used for .CSV**) with the code for the initial analysis for the CSV - take it as showing my work.\n",
    "\n",
    "**DEALING WITH OBJECTS**<br/>\n",
    "There are 4 columns that are data type object (meaning that have embeded further data). As part of the cleaning process, one of them was analyzed **`m_header`** and the majority of the content is the same. I took the desicion of removing the **`objects`**. However, depending on the analysis, it could be the case that some data in those objects could be required. As reference, the table below presents sample data.\n",
    "\n",
    "| Object | Content|\n",
    "|---|---|\n",
    "| m_header | <small>`{'m_packet_format': 2021, 'm_game_major_version': 1, 'm_game_minor_version': 14, 'm_packet_version': 1, 'm_packet_id': 1, 'm_session_uid': 13002103581294142936, 'm_session_time': 2803.836, 'm_frame_identifier': 82458, 'm_player_car_index': 0, 'm_secondary_player_car_index': 255}`<br/>`Name: m_header, dtype: object`|\n",
    "| m_marshal_zones | `[{'m_zone_start': 0.088, 'm_zone_flag': 0}, {'m_zone_start': 0.167, 'm_zone_flag': 0}, {'m_zone_start': 0.23800000000000002, 'm_zone_flag': 0},`<br/>` {'m_zone_start': 0.298, 'm_zone_flag': 0}, {'m_zone_start': 0.353, 'm_zone_flag': 0}, {'m_zone_start': 0.41200000000000003, 'm_zone_flag': 0}, {'m_zone_start': 0.45, 'm_zone_flag': 0}, {'m_zone_start': 0.495, 'm_zone_flag': 0}, {'m_zone_start': 0.54, 'm_zone_flag': 0}, {'m_zone_start': 0.62, 'm_zone_flag': 0}, {'m_zone_start': 0.6900000000000001, 'm_zone_flag': 0}, {'m_zone_start': 0.726, 'm_zone_flag': 0}, {'m_zone_start': 0.789, 'm_zone_flag': 0}, {'m_zone_start': 0.8310000000000001, 'm_zone_flag': 0}, {'m_zone_start': 0.925, 'm_zone_flag': 0}, {'m_zone_start': 0.997, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}, {'m_zone_start': 0, 'm_zone_flag': 0}]` <br/> `Name: m_marshal_zones, dtype: object` <small/>|\n",
    "| gamehost |<small>`f1digest`<br/>`Name: gamehost, dtype: object`<small/>|\n",
    "| m_weather_forecast_samples |<small>`[{'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_session_type': 0, 'm_time_offset': 0, 'm_weather': 0, 'm_track_temperature': 0, 'm_track_temperature_change': 0, 'm_air_temperature': 0, 'm_air_temperature_change': 0, 'm_rain_percentage': 0}, {'m_sessio...`<br/>`Name: m_weather_forecast_samples, dtype: object`<small/>|\n",
    "\n",
    "**DEALING WITH STANDARD DEVIATION ZERO**<br/>\n",
    "The column m_sli_pro_native_support showed standard deviation zero (no variation) with a unique value of zero. So this coulumn was dropped out of the dataframe.\n",
    "\n",
    "**DEALING WITH `timestamp`**<br/>\n",
    "This column `timestamp` is a `datetime` type so I split the day, month, year to asses the need to keep or remove some of that information. The year is the same (2022) so I removed that one and only added columns `month`, `day` in the `df_weather` dataframe.\n",
    "\n",
    "**DEALING WITH DUPLICATE ROWS**<br/>\n",
    "I found about 7,148 duplicated rows. One case was check and then removed all duplicates but keeping the first occurance.\n",
    "\n",
    "| Before | After |\n",
    "|---|---|\n",
    "| 339,692 entries<br/>Total 41 columns<br/>dtypes: datetime64\\[ns](1 col), int64(36 cols), object(4 cols)| 332,544 entries<br/>Total 38 columns<br/>dtypes: datetime64\\[ns](1 col), int32(2 col), int64(35 col)|\n",
    "\n",
    "\n",
    "**REFERENCES**<br/>\n",
    "\n",
    "[4] With pandas cheat sheet http://pandas.pydata.org. (n.d.-b). https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf \n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization (e.g., histograms, scatterplots, etc.)\n",
    "- You should write a brief summary of the insights and conclusions you have drawn from your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Related to driver/car assist** ####\n",
    "\n",
    "|Column|Description|Note|\n",
    "|---|---|---|\n",
    "|m_braking_assist                |0 = off, 1 = low, 2 = medium, 3 = high|Treat as buckets/categories (ordinal). |\n",
    "|m_gearbox_assist                |1 = manual, 2 = manual & suggested gear, 3 = auto|Treat as categorical.|\n",
    "|m_ersassist                     |0 = off, 1 = on|Treat as binary|\n",
    "|m_steering_assist               |0 = off, 1 = on|Treat as binary|\n",
    "|m_drsassist                     |0 = off, 1 = on|Treat as binary|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking Assist ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table to check the count per unique value and sort based on the value\n",
    "value_counts = df_weather['m_braking_assist'].value_counts().sort_index()\n",
    "percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "# Combine value counts and percentages into a DataFrame\n",
    "display(pd.DataFrame({'Count': value_counts, 'Percentage': percentages}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values and sort them\n",
    "unique_values = np.sort(df_weather['m_braking_assist'].unique())\n",
    "print(\"m_braking_assist - categories found:\", unique_values)\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: \"0-Off\",\n",
    "    1: \"1-Low\",\n",
    "    2: \"2-Medium\",\n",
    "    3: \"3-High\"\n",
    "}\n",
    "\n",
    "# Set the figure size\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Count the occurrences of each category and sort by index\n",
    "category_counts = df_weather['m_braking_assist'].value_counts().sort_index()\n",
    "\n",
    "# Add any missing categories with 0 count\n",
    "for category in category_mapping.keys():\n",
    "    if category not in category_counts.index:\n",
    "        category_counts[category] = 0\n",
    "\n",
    "# Re-sort the categories after adding missing ones\n",
    "category_counts = category_counts.sort_index()\n",
    "\n",
    "# Plot the bar chart\n",
    "ax = category_counts.plot(kind='bar')\n",
    "\n",
    "# Label x and y axes\n",
    "plt.xlabel('m_braking_assist')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of m_braking_assist')\n",
    "\n",
    "# Create a list of labels using the category mapping\n",
    "xticklabels = [category_mapping[category] for category in category_counts.index]\n",
    "\n",
    "# Set the x-tick labels\n",
    "ax.set_xticklabels(xticklabels)\n",
    "\n",
    "# Rotate the labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function so we can reuse easily\n",
    "\n",
    "def bar_plot(df_in,col_name,category_mapping):      # df_in input dataframe, col_name column name, category_mapping dictionary\n",
    "\n",
    "    # Get unique values and sort them\n",
    "    unique_values = np.sort(df_in[col_name].unique())\n",
    "    print(col_name,\"- categories found:\", unique_values,\"\\n\")   # to debug\n",
    "\n",
    "    # Get value counts and percentage\n",
    "    value_counts = df_in[col_name].value_counts().sort_index()\n",
    "    percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "    # Combine value counts and percentages into a DataFrame\n",
    "    display(pd.DataFrame({'Count': value_counts, 'Percentage': percentages}))\n",
    "\n",
    "    # Set the figure size\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "\n",
    "    # Count the occurrences of each category and sort by index\n",
    "    category_counts = df_in[col_name].value_counts().sort_index()\n",
    "\n",
    "    # Add any missing categories with 0 count\n",
    "    for category in category_mapping.keys():\n",
    "        if category not in category_counts.index:\n",
    "            category_counts[category] = 0\n",
    "\n",
    "    # Re-sort the categories after adding missing ones\n",
    "    category_counts = category_counts.sort_index()\n",
    "\n",
    "    # Plot the bar chart\n",
    "    ax = category_counts.plot(kind='bar')\n",
    "\n",
    "    # Label x and y axes\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of '+ col_name)\n",
    "\n",
    "    # Create a list of labels using the category mapping\n",
    "    xticklabels = [category_mapping[category] for category in category_counts.index]\n",
    "\n",
    "    # Set the x-tick labels\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "\n",
    "    # Rotate the labels for better readability\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Add count labels on top of each bar\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "    # Ensure layout is tight to avoid clipping\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug the function bar_plot\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: \"0-Off\",\n",
    "    1: \"1-Low\",\n",
    "    2: \"2-Medium\",\n",
    "    3: \"3-High\"\n",
    "}\n",
    "\n",
    "bar_plot(df_weather,'m_braking_assist',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gearbox assist ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts and percentage\n",
    "value_counts = df_weather['m_gearbox_assist'].value_counts().sort_index()\n",
    "percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "# Combine value counts and percentages into a DataFrame\n",
    "display(pd.DataFrame({'Count': value_counts, 'Percentage': percentages}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    1: \"1-Manual\",\n",
    "    2: \"2-Manual \\n& suggested gear\",\n",
    "    3: \"3-Auto\"\n",
    "}\n",
    "\n",
    "bar_plot(df_weather,'m_gearbox_assist',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERS Assist ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: \"0-Off\",\n",
    "    1: \"1-On\",\n",
    "}\n",
    "\n",
    "bar_plot(df_weather,'m_ersassist',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steering Assist ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: \"0-Off\",\n",
    "    1: \"1-On\",\n",
    "}\n",
    "\n",
    "bar_plot(df_weather,'m_steering_assist',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRS Assist ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: \"0-Off\",\n",
    "    1: \"1-On\",\n",
    "}\n",
    "\n",
    "bar_plot(df_weather,'m_drsassist',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis driver/car assist ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion that will plot correlation matrix for certain columns in a given df_in\n",
    "\n",
    "def plot_correlation_matrix(df_in, selected_columns):\n",
    "    df_selected = df_in[selected_columns]\n",
    "\n",
    "    # Computing correlation matrix\n",
    "    correlation_matrix = df_selected.corr()\n",
    "\n",
    "    # Display correlation table\n",
    "    print(\"Correlation Table:\")\n",
    "    print(correlation_matrix)\n",
    "\n",
    "    # Plotting heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['m_braking_assist', 'm_gearbox_assist', 'm_ersassist', 'm_steering_assist', 'm_drsassist']\n",
    "plot_correlation_matrix(df_weather, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pit related** ####\n",
    "\n",
    "|Column|Description|Notes|\n",
    "|---|---|---|\n",
    "|m_pit_assist                    |0 = off, 1 = on| Binary|\n",
    "|m_pit_release_assist            |0 = off, 1 = on| Binary|\n",
    "|m_pit_stop_window_ideal_lap     |Ideal lap to pit on for current strategy (player)| Quantitative|\n",
    "|m_pit_stop_window_latest_lap    |Latest lap to pit on for current strategy (player)| Quantitatve|\n",
    "|m_pit_stop_rejoin_position      |Predicted position to rejoin at (player)| Ordinal|\n",
    "|m_pit_speed_limit               |Pit speed limit in kilometres per hour|  Quantitative variable|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pit Assist ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: \"0-Off\",\n",
    "    1: \"1-On\",\n",
    "}\n",
    "\n",
    "bar_plot(df_weather,'m_pit_assist',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put release assist ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: \"0-Off\",\n",
    "    1: \"1-On\",\n",
    "}\n",
    "\n",
    "bar_plot(df_weather,'m_pit_release_assist',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pit Stop Window Ideal Lap ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to reuse\n",
    "\n",
    "# Plot histogram\n",
    "def plot_histogram(col_name, df, unit=None, number_bins=None):\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 3))\n",
    "    if number_bins==None:\n",
    "        plt.hist(df[col_name])\n",
    "    else:\n",
    "        plt.hist(df[col_name],bins=number_bins)\n",
    "        \n",
    "    if unit != None:\n",
    "        label_x = col_name+\" [\"+unit+\"]\"\n",
    "    else:\n",
    "        label_x = col_name\n",
    "    plt.xlabel(label_x)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.title('Histogram of '+col_name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    display(df[col_name].describe())\n",
    "\n",
    "plot_histogram('m_pit_stop_window_ideal_lap',df_weather, unit=\"lap\", number_bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pit Stop Window Latest Lap ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_pit_stop_window_latest_lap',df_weather,number_bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pit stop rejoin position ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to reuse for similar case of ordinal\n",
    "\n",
    "def plot_ordinal_bars(col_name, df):\n",
    "    # Get value counts and percentage\n",
    "    value_counts = df[col_name].value_counts().sort_index()\n",
    "    percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "    # Combine value counts and percentages into a DataFrame\n",
    "    display(pd.DataFrame({'Count': value_counts, 'Percentage': percentages}))\n",
    "\n",
    "    # Plot the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    # Combine value counts and percentages into a DataFrame\n",
    "    df_counts = pd.DataFrame({'Count': value_counts, 'Percentage': percentages})\n",
    "    df_counts['Count'].plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Add labels\n",
    "    ax.set_xlabel(col_name)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Bar Plot of '+col_name+' Frequency')\n",
    "\n",
    "    # Rotate x-axis labels for readability\n",
    "    ax.set_xticks(range(len(value_counts)))\n",
    "    ax.set_xticklabels(value_counts.index, rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_ordinal_bars('m_pit_stop_rejoin_position', df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pit Speed Limit ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_pit_speed_limit',df_weather,unit=\"km/hr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix for Pit Stop related columns ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns for correlation analysis\n",
    "selected_columns = ['m_pit_assist', 'm_pit_release_assist', 'm_pit_stop_window_ideal_lap', 'm_pit_stop_window_latest_lap', 'm_pit_stop_rejoin_position', 'm_pit_speed_limit']\n",
    "\n",
    "plot_correlation_matrix(df_weather, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Session related** ####\n",
    "|Column|Description|Notes|\n",
    "|---|---|---|\n",
    "|m_session_type|0 = unknown, 1 = P1, 2 = P2, 3 = P3, 4 = Short P, 5 = Q1, 6 = Q2, 7 = Q3, <br/>8 = Short Q, 9 = OSQ, 10 = R, 11 = R2, 12 = R3, 13 = Time Trial|Categorical but some sub-categories can be seen as ordinal,<br/> like Practice -> Qualifying :: P1->P2->P3 then Q1->Q2->Q3 |\n",
    "|m_session_link_identifier|Identifier for season - persists across saves|Assumed to be some sort of index or key|\n",
    "|m_session_time_left|Time left in session in seconds|Quantitative|\n",
    "|m_session_duration |Session duration in seconds|Quantitative|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session type ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0 : 'unknown', \n",
    "    1 : 'P1', \n",
    "    2 : 'P2', \n",
    "    3 : 'P3', \n",
    "    4 : 'Short P', \n",
    "    5 : 'Q1', \n",
    "    6 : 'Q2', \n",
    "    7 : 'Q3', \n",
    "    8 : 'Short Q', \n",
    "    9 : 'OSQ', \n",
    "    10 : 'Race', \n",
    "    11 : 'Race 2', \n",
    "    12 : 'Race 3', \n",
    "    13 : 'Time Trial'\n",
    "}\n",
    "\n",
    "\n",
    "bar_plot(df_weather,'m_session_type',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session Link Identifier ####\n",
    "\n",
    "m_session_link_identifier       | Identifier for session - persists across save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "plt.hist(df_weather['m_session_link_identifier'],bins=200)\n",
    "plt.xlabel('m_session_link_identifier')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of m_session_link_identifier')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantity for zero looks very high and base on the definition of the column it could mean that the value is not available or not applicable\n",
    "# Lets check the count of zero vs greater than zero in column 'm_session_link_identifier'\n",
    "# Count of zero vs greater than zero in column 'm_session_link_identifier'\n",
    "count_zero = (df_weather['m_session_link_identifier'] == 0).sum()\n",
    "count_greater_than_zero = (df_weather['m_session_link_identifier'] > 0).sum()\n",
    "\n",
    "\n",
    "print(f\"Count equal zero: {count_zero}\\tPercentage: {count_zero / (count_zero + count_greater_than_zero) * 100:.2f}%\")\n",
    "print(f\"Count of > zero: {count_greater_than_zero}\\tPercentage: {count_greater_than_zero / (count_zero + count_greater_than_zero) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot again but removing zero\n",
    "# Filter the data for 'm_session_link_identifier' > 0\n",
    "filtered_data = df_weather[df_weather['m_session_link_identifier'] > 0]\n",
    "\n",
    "# Plot the histogram\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "plt.hist(filtered_data['m_session_link_identifier'], bins=200)\n",
    "plt.xlabel('m_session_link_identifier')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of m_session_link_identifier (values > 0)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session time left ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_session_time_left', df_weather,unit=\"secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session duration ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_session_duration', df_weather, unit=\"secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation between Session type .vs. Session duration ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there are multiple distributions (or peaks) within session duration\n",
    "# So, I look at session duration per session type\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: 'Unknown', \n",
    "    1: 'P1', 2: 'P2', 3: 'P3', 4: 'Short P', \n",
    "    5: 'Q1', 6: 'Q2', 7: 'Q3', 8: 'Short Q', 9: 'OSQ', \n",
    "    10: 'Race', 11: 'Race 2', 12: 'Race 3', \n",
    "    13: 'Time Trial'}\n",
    "\n",
    "# Use pyplot.get_cmap() to get the colormap\n",
    "colormap = plt.get_cmap('gist_rainbow', len(category_mapping))  # Choose the colormap\n",
    "\n",
    "# Get unique session types\n",
    "session_types = df_weather['m_session_type'].unique()\n",
    "num_types = len(session_types)\n",
    "\n",
    "# Define grid size (4x4)\n",
    "rows, cols = 5, 3\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through session types and plot histograms\n",
    "for i, session_type in enumerate(session_types):\n",
    "    subset = df_weather[df_weather['m_session_type'] == session_type]\n",
    "    axes[i].hist(subset['m_session_duration'], bins=30, color=colormap(i), edgecolor='black')\n",
    "    axes[i].set_title(f'Session Type: {category_mapping[session_type]}')\n",
    "    axes[i].set_xlabel('m_session_duration' + ' [secs]')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session type vs. Session time left ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there are multiple distributions (or peaks) within session time left\n",
    "# So, I look at session time left per session type\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: 'Unknown', \n",
    "    1: 'P1', 2: 'P2', 3: 'P3', 4: 'Short P', \n",
    "    5: 'Q1', 6: 'Q2', 7: 'Q3', 8: 'Short Q', 9: 'OSQ', \n",
    "    10: 'Race', 11: 'Race 2', 12: 'Race 3', \n",
    "    13: 'Time Trial'}\n",
    "\n",
    "# Use pyplot.get_cmap() to get the colormap\n",
    "colormap = plt.get_cmap('gist_rainbow', len(category_mapping))  # Choose the colormap\n",
    "\n",
    "# Get unique session types\n",
    "session_types = df_weather['m_session_type'].unique()\n",
    "num_types = len(session_types)\n",
    "\n",
    "# Define grid size (4x4)\n",
    "rows, cols = 5, 3\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through session types and plot histograms\n",
    "for i, session_type in enumerate(session_types):\n",
    "    subset = df_weather[df_weather['m_session_type'] == session_type]\n",
    "    axes[i].hist(subset['m_session_time_left'], bins=30, color=colormap(i), edgecolor='black')\n",
    "    axes[i].set_title(f'Session Type: {category_mapping[session_type]}')\n",
    "    axes[i].set_xlabel('m_session_time_left' + ' [secs]')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session type .vs. Session identifier ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: 'Unknown', \n",
    "    1: 'P1', 2: 'P2', 3: 'P3', 4: 'Short P', \n",
    "    5: 'Q1', 6: 'Q2', 7: 'Q3', 8: 'Short Q', 9: 'OSQ', \n",
    "    10: 'Race', 11: 'Race 2', 12: 'Race 3', \n",
    "    13: 'Time Trial'}\n",
    "\n",
    "# Use pyplot.get_cmap() to get the colormap\n",
    "colormap = plt.get_cmap('gist_rainbow', len(category_mapping))  # Choose the colormap\n",
    "\n",
    "# Get unique session types\n",
    "session_types = df_weather['m_session_type'].unique()\n",
    "num_types = len(session_types)\n",
    "\n",
    "# Define grid size (4x4)\n",
    "rows, cols = 5, 3\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through session types and plot histograms\n",
    "for i, session_type in enumerate(session_types):\n",
    "    subset = df_weather[df_weather['m_session_type'] == session_type]\n",
    "    axes[i].hist(subset['m_session_link_identifier'], bins=30, color=colormap(i), edgecolor='black')\n",
    "    axes[i].set_title(f'Session Type: {category_mapping[session_type]}')\n",
    "    axes[i].set_xlabel('m_session_link_identifier')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix for Session related columns ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns for correlation analysis\n",
    "selected_columns = ['m_session_type', 'm_session_link_identifier', 'm_session_time_left', 'm_session_duration']\n",
    "\n",
    "plot_correlation_matrix(df_weather, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### timestamp ####\n",
    "\n",
    "timestamp | timestamp for when the packet was received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "fig = plt.figure(figsize=(12, 3))\n",
    "plt.hist(df_weather['timestamp'],bins=1000)     # increasing bins to see the \"buckets\"\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of timestamp')\n",
    "\n",
    "# rotate labels for a better view\n",
    "plt.xticks(rotation=90, ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by day (mm-dd-yyyy format) and count occurrences\n",
    "daily_counts = df_weather.groupby(df_weather['timestamp'].dt.strftime('%m-%d-%Y')).size()\n",
    "\n",
    "# Display the counts\n",
    "print(daily_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot using format mm-dd-yyyy\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.bar(daily_counts.index, daily_counts.values)\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=90, ha='center')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Date (dd-mm-yyyy)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Bar plot Daily Counts')\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the figure\n",
    "fig = plt.figure(figsize=(13, 6))\n",
    "\n",
    "# Set the number of bins\n",
    "bins = 500\n",
    "\n",
    "# Get unique m_track_id values\n",
    "unique_track_ids = df_weather['m_track_id'].unique()\n",
    "\n",
    "# Use pyplot.get_cmap() to get the colormap\n",
    "colormap = plt.get_cmap('gist_rainbow', len(unique_track_ids))  # Choose the colormap\n",
    "\n",
    "# Plot the histogram for each m_track_id group with different colors\n",
    "for i, track_id in enumerate(unique_track_ids):\n",
    "    subset = df_weather[df_weather['m_track_id'] == track_id]\n",
    "    plt.hist(subset['timestamp'], bins=bins, alpha=0.6, color=colormap(i), label=f'Track ID {track_id}')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Timestamp')\n",
    "\n",
    "# Rotate labels for better readability\n",
    "plt.xticks(rotation=90, ha=\"center\")\n",
    "\n",
    "# Add a legend\n",
    "# plt.legend()\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.5), ncol=7)\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Track related** ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Column|Description|Notes|\n",
    "|---|---|---|\n",
    "|m_track_id                      |-1 for unknown, 0-21 for tracks |Categorical|\n",
    "|m_track_temperature             |Track temp. in degrees celsius|Quantitative|\n",
    "|m_track_length                  |Track length in metres|Quantitative|\n",
    "|m_num_marshal_zones             |Number of marshal zones to follow |Quantitative|\n",
    "|m_safety_car_status             |0 = no safety car, 1 = full, 2 = virtual, 3 = formation lap|Categorical|\n",
    "|m_total_laps                    |Total number of laps in this race|Quantitative|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track ID ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot as ordinal to see the unique values\n",
    "plot_ordinal_bars('m_track_id', df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track Temperature ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_track_temperature', df_weather, unit=\"\\u00b0C\", number_bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track Length ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_track_length', df_weather, unit=\"mts\", number_bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marshal Zones ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_num_marshal_zones', df_weather, unit=\"#\", number_bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Safety Cart Status ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0 : '0 = no safety car', \n",
    "    1 : '1 = full', \n",
    "    2 : '2 = virtual', \n",
    "    3 : '3 = formation lap'\n",
    "}\n",
    "\n",
    "\n",
    "bar_plot(df_weather,'m_safety_car_status',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Laps ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_total_laps', df_weather, unit=\"# laps\", number_bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot as ordinal to see the unique values - likely there is a correlation with the track and session\n",
    "plot_ordinal_bars('m_total_laps', df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis - Track related ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns for correlation analysis\n",
    "selected_columns = ['m_track_id', 'm_track_temperature', 'm_track_length', 'm_num_marshal_zones', 'm_safety_car_status', 'm_total_laps']\n",
    "\n",
    "plot_correlation_matrix(df_weather, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Weather related** ####\n",
    "\n",
    "|Column|Description|Notes|\n",
    "|---|---|---|\n",
    "|m_air_temperature    |Air temp. in degrees celsius|Quantitative|\n",
    "|m_forecast_accuracy  |0 = Perfect, 1 = Approximate.|Binary|\n",
    "|m_weather            |Weather - 0 = clear, 1 = light cloud, 2 = overcast, 3 = light rain, 4 = heavy rain, 5 = storm|Ordinal|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Air Temperature ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_air_temperature', df_weather, unit=\"\\u00b0C\", number_bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecast accuracy ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: \"0-Perfect\",\n",
    "    1: \"1-Aproximate\",\n",
    "}\n",
    "\n",
    "bar_plot(df_weather,'m_forecast_accuracy',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0 : '0 = clear', \n",
    "    1 : '1 = light cloud', \n",
    "    2 : '2 = overcast', \n",
    "    3 : '3 = light rain',\n",
    "    4: '4 = heavy rain',\n",
    "    5: '5 = strom'}\n",
    "\n",
    "bar_plot(df_weather,'m_weather',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Correlation Weather related** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns for correlation analysis\n",
    "selected_columns = ['m_air_temperature', 'm_forecast_accuracy', 'm_weather']\n",
    "\n",
    "plot_correlation_matrix(df_weather, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Other elements** ####\n",
    "\n",
    "|Columns|Description|Notes|\n",
    "|---|---|---|\n",
    "|m_formula                 |Formula, 0 = F1 Modern, 1 = F1 Classic, 2 = F2, 3 = F1 Generic|Categorical|\n",
    "|m_dynamic_racing_line_type|0 = 2D, 1 = 3D|Binary|\n",
    "|m_dynamic_racing_line     |0 = off, 1 = corners only, 2 = full|Categorical|\n",
    "|m_ai_difficulty           |AI Difficulty rating â€“ 0-110|Quantitative|\n",
    "|m_network_game            |0 = offline, 1 = online|Binary|\n",
    "|m_game_paused             |Whether the game is paused|Binary|\n",
    "|m_is_spectating           |Whether the player is spectating|Binary|\n",
    "|m_spectator_car_index     |Index of the car being spectated||\n",
    "|m_season_link_identifier  |Identifier for season - persists across saves||\n",
    "|m_weekend_link_identifier |Identifier for weekend - persists across saves||\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0 : '0 = F1 Modern', \n",
    "    1 : '1 = F1 Classic', \n",
    "    2 : '2 = F2', \n",
    "    3 : '3 = F1 Generic'}\n",
    "\n",
    "bar_plot(df_weather,'m_formula',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Racing line type ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0 : '0 = 2D', \n",
    "    1 : '1 = 3D'}\n",
    "\n",
    "bar_plot(df_weather,'m_dynamic_racing_line_type',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Racing Line ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0 : '0 = off', \n",
    "    1 : '1 = corners only', \n",
    "    2 : '2 = full'}\n",
    "\n",
    "bar_plot(df_weather,'m_dynamic_racing_line',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI difficulty ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "\n",
    "plot_histogram('m_ai_difficulty', df_weather, unit=\"level\", number_bins=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Game ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0 : '0 = offline', \n",
    "    1 : '1 = online'}\n",
    "\n",
    "bar_plot(df_weather,'m_network_game',category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game paused ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot as ordinal to see the unique values\n",
    "plot_ordinal_bars('m_game_paused', df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whether the player is spectating ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot as ordinal to see the unique values\n",
    "plot_ordinal_bars('m_is_spectating', df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectator car index ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot as ordinal to see the unique values\n",
    "plot_ordinal_bars('m_spectator_car_index', df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is Spectating vs Spectator Car Index ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category mapping\n",
    "category_mapping = {\n",
    "    0: '0', \n",
    "    1: '1'}\n",
    "\n",
    "# Use pyplot.get_cmap() to get the colormap\n",
    "colormap = plt.get_cmap('gist_rainbow', len(category_mapping))  # Choose the colormap\n",
    "\n",
    "# Get unique session types\n",
    "session_types = df_weather['m_is_spectating'].unique()\n",
    "num_types = len(session_types)\n",
    "\n",
    "# Define grid size (4x4)\n",
    "rows, cols = 5, 3\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through session types and plot histograms\n",
    "for i, session_type in enumerate(session_types):\n",
    "    subset = df_weather[df_weather['m_is_spectating'] == session_type]\n",
    "    axes[i].hist(subset['m_spectator_car_index'], bins=30, color=colormap(i), edgecolor='black')\n",
    "    axes[i].set_title(f'm_is_spectating: {category_mapping[session_type]}')\n",
    "    axes[i].set_xlabel('m_spectator_car_index')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation for other columns ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns for correlation analysis\n",
    "selected_columns = ['m_formula','m_dynamic_racing_line_type','m_dynamic_racing_line', 'm_ai_difficulty', 'm_network_game', 'm_game_paused', 'm_is_spectating', 'm_spectator_car_index']\n",
    "\n",
    "plot_correlation_matrix(df_weather, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Map\n",
    "numeric_variables = df_weather.select_dtypes(include=np.number)\n",
    "correlation_table = numeric_variables.corr()\n",
    "correlation_table\n",
    "\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(correlation_table, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but for Spearman\n",
    "correlation_table = numeric_variables.corr(method='spearman')\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(correlation_table, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Spearman Corr. Table')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Insights Summary ##\n",
    "\n",
    "`m_braking_assist`\n",
    "\n",
    "- Vast majority (92.66%) with bracking assist off.\n",
    "- No samples for breaking assistant category low.\n",
    "\n",
    "`m_session_link_identifier`\n",
    "\n",
    "- Found 23.84% of the observations with value zero. That can indicate that for those observations the identifier is not applicable or not available.\n",
    "- Doing the histogram with values greather than one looks to be a bit more uniform.\n",
    "\n",
    "`m_pit_release_assist`\n",
    "\n",
    "- Binary variable where majority (91.66%) of observations with pit release assist off.\n",
    "\n",
    "`timestamp`\n",
    "\n",
    "- Not a continues distribution of timestamps but rather buckets. This aligns with the observation during cleaning for certan days/months of the 2022. In particular, from 01-05-2022 until 02-12-2022.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "\n",
    "---\n",
    "----\n",
    "</span>\n",
    "\n",
    "## FOR REFERENCE: OLD Analysis used for .CSV ##\n",
    "\n",
    "This section is added to show my work. Execution STOPS here as this is old and not the final analysis.\n",
    "\n",
    "<span style=\"color:red\">\n",
    "\n",
    "---\n",
    "--- \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will start reviewing the columns that are likely irrelevant, e.g. same value.\n",
    "# For that will use those with standard deviation zero (from summary stats above) as possible list:\n",
    "# M_PACKET_FORMAT\n",
    "# M_GAME_MAJOR_VERSION\n",
    "# M_PACKET_VERSION\n",
    "# M_PACKET_ID\n",
    "# M_SECONDARY_PLAYER_CAR_INDEX\n",
    "# M_SLI_PRO_NATIVE_SUPPORT\n",
    "# M_SAFETY_CAR_STATUS\n",
    "\n",
    "\n",
    "# Will keep an array of the columns to drop\n",
    "columns_to_drop = []\n",
    "\n",
    "display(df_weather['M_PACKET_FORMAT'].describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can be drop because it is constant no matter the observation\n",
    "columns_to_drop.append('M_PACKET_FORMAT')\n",
    "\n",
    "# Continue with next column\n",
    "display(df_weather['M_GAME_MAJOR_VERSION'].describe().transpose())\n",
    "display(df_weather['M_GAME_MAJOR_VERSION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can be drop because it is constant no matter the observation\n",
    "columns_to_drop.append('M_GAME_MAJOR_VERSION')\n",
    "\n",
    "# Continue with next column\n",
    "display(df_weather['M_PACKET_VERSION'].describe().transpose())\n",
    "display(df_weather['M_PACKET_VERSION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can be drop because it is constant no matter the observation\n",
    "columns_to_drop.append('M_PACKET_VERSION')\n",
    "\n",
    "# Continue with next column\n",
    "display(df_weather['M_PACKET_ID'].describe().transpose())\n",
    "display(df_weather['M_PACKET_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can be drop because it is constant no matter the observation\n",
    "columns_to_drop.append('M_PACKET_ID')\n",
    "\n",
    "# Continue with next column\n",
    "display(df_weather['M_SECONDARY_PLAYER_CAR_INDEX'].describe().transpose())\n",
    "display(df_weather['M_SECONDARY_PLAYER_CAR_INDEX'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can be drop because it is constant no matter the observation\n",
    "columns_to_drop.append('M_SECONDARY_PLAYER_CAR_INDEX')\n",
    "\n",
    "# Continue with next column\n",
    "display(df_weather['M_SLI_PRO_NATIVE_SUPPORT'].describe().transpose())\n",
    "display(df_weather['M_SLI_PRO_NATIVE_SUPPORT'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can be drop because it is constant no matter the observation\n",
    "columns_to_drop.append('M_SLI_PRO_NATIVE_SUPPORT')\n",
    "\n",
    "# Continue with next column\n",
    "display(df_weather['M_SAFETY_CAR_STATUS'].describe().transpose())\n",
    "display(df_weather['M_SAFETY_CAR_STATUS'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can be drop because it is constant no matter the observation\n",
    "columns_to_drop.append('M_SAFETY_CAR_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last columns 'Unnamed: 58' has zero count so that one can be dropped as well\n",
    "df_weather = df_weather.drop(columns=['Unnamed: 58'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the columns will less observations\n",
    "df_weather.count().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The are some columns with less than 3572328 rows and for those some action could be needed if any of those columns is used later\n",
    "E.g. as part of modelling.\n",
    "\n",
    "For now, will just list columns - but no action will be done.\n",
    "\n",
    "|Column| Count|\n",
    "|---|---|\n",
    "|M_ZONE_START                                      | 974274\n",
    "|M_ZONE_FLAG                                       | 974274\n",
    "|M_WEATHER_FORECAST_SAMPLES_M_AIR_TEMPERATURE      |2598054\n",
    "|M_WEATHER_FORECAST_SAMPLES_M_SESSION_TYPE         |2598054\n",
    "|M_TIME_OFFSET                                     |2598054\n",
    "|M_WEATHER_FORECAST_SAMPLES_M_WEATHER              |2598054\n",
    "|M_WEATHER_FORECAST_SAMPLES_M_TRACK_TEMPERATURE    |2598054\n",
    "|M_TRACK_TEMPERATURE_CHANGE                        |2598054\n",
    "|M_AIR_TEMPERATURE_CHANGE                          |2598054\n",
    "|M_RAIN_PERCENTAGE                                 |2598054\n",
    "|GAMEHOST                                          |2663112\n",
    "\n",
    "With 3572327 observations:\n",
    "|Column|Column|Column|\n",
    "|---|---|---|\n",
    "|M_DRSASSIST              |M_NUM_MARSHAL_ZONES\t|M_NETWORK_GAME                                    \n",
    "|M_TOTAL_LAPS             |M_STEERING_ASSIST    |M_IS_SPECTATING                                   \n",
    "|M_DYNAMIC_RACING_LINE    |M_AI_DIFFICULTY               |M_PIT_SPEED_LIMIT                                 \n",
    "|M_PIT_STOP_REJOIN_POSITION   |M_SESSION_DURATION        |M_SESSION_TIME_LEFT                               \n",
    "|M_DYNAMIC_RACING_LINE_TYPE   |M_WEEKEND_LINK_IDENTIFIER |M_WEATHER                                         \n",
    "|M_PIT_STOP_WINDOW_LATEST_LAP |M_GAME_MINOR_VERSION      |M_GEARBOX_ASSIST                                  \n",
    "|M_SESSION_UID                |M_SESSION_TIME            |M_FRAME_IDENTIFIER                                \n",
    "|M_PLAYER_CAR_INDEX           |M_BRAKING_ASSIST          |M_SESSION_LINK_IDENTIFIER                         \n",
    "|M_PIT_RELEASE_ASSIST         |TIMESTAMP                 |M_PIT_STOP_WINDOW_IDEAL_LAP                       \n",
    "|M_SPECTATOR_CAR_INDEX        |M_TRACK_TEMPERATURE       |M_GAME_PAUSED                                     \n",
    "|M_FORECAST_ACCURACY          |M_AIR_TEMPERATURE         |M_NUM_WEATHER_FORECAST_SAMPLES                    \n",
    "|M_TRACK_ID                   |M_ERSASSIST               |M_FORMULA                                         \n",
    "|M_SEASON_LINK_IDENTIFIER     |M_PIT_ASSIST              |M_TRACK_LENGTH                                    \n",
    "|M_SESSION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Data visualization (e.g., histograms, scatterplots, etc.)\n",
    "- You should write a brief summary of the insights and conclusions you have drawn from your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Item|Insights|\n",
    "|---|---|\n",
    "|M_WEATHER|- 74.59% of data points under clear weather.<br/>- No data for categories: 3(light rain) and 4 (heavy rain).<br/>- Ordinal data as categories has an explicit order, so important to consider for future analysis.\n",
    "|M_AIR_TEMPERATURE |- Integer values, instead of continuous as you may expect.<br/>- When plotting histogram  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Will check that the data aligns with the definition of some categorical columns\n",
    "# M_WEATHER should be 0 = clear, 1 = light cloud, 2 = overcast, 3 = light rain, 4 = heavy rain, 5 = storm\n",
    "\n",
    "# Get unique values and sort them\n",
    "unique_values = np.sort(df_weather['M_WEATHER'].unique())\n",
    "print(\"M_WEATHER - categories found:\", unique_values)\n",
    "\n",
    "# Define category mapping\n",
    "category_mapping = {\n",
    "        0: \"0-Clear\",\n",
    "        1: \"1-Light Cloud\",\n",
    "        2: \"2-Overcast\",\n",
    "        3: \"3-Light Rain\",\n",
    "        4: \"4-Heavy Rain\",\n",
    "        5: \"5-Storm\"\n",
    "    }\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "# plt.hist(df_weather['M_WEATHER'],bins=100)\n",
    "# will use bars as it is more clear for a column that is categorical\n",
    "ax = df_weather['M_WEATHER'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('M_WEATHER')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of M_WEATHER')\n",
    "\n",
    "# Debugging: Get the x-tick labels text \n",
    "xticks = ax.get_xticklabels()\n",
    "# for tick in xticks:\n",
    "#    print(tick.get_text())\n",
    "\n",
    "# Create a list of labels using the category mapping\n",
    "xticklabels = [category_mapping[int(tick.get_text())] for tick in xticks]\n",
    "\n",
    "# Set the x-tick labels\n",
    "ax.set_xticklabels(xticklabels)\n",
    "\n",
    "# Rotate the labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the category mapping to the 'M_WEATHER' column\n",
    "df_weather['M_WEATHER_LABEL'] = df_weather['M_WEATHER'].map(category_mapping)\n",
    "\n",
    "# Create a frequency table with counts and percentages\n",
    "frequency_table = df_weather['M_WEATHER_LABEL'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "frequency_table.columns = ['M_WEATHER', 'Count']\n",
    "\n",
    "# Add a percentage column\n",
    "frequency_table['Percentage'] = (frequency_table['Count'] / len(df_weather[\"M_WEATHER\"])) * 100\n",
    "\n",
    "# Round the percentage values for readability\n",
    "frequency_table['Percentage'] = frequency_table['Percentage'].round(2)\n",
    "\n",
    "# Display the frequency table\n",
    "display(frequency_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M_AIR_TEMPERATURE in C\n",
    "\n",
    "# Get unique values and sort them\n",
    "unique_values = np.sort(df_weather['M_AIR_TEMPERATURE'].unique())\n",
    "print(\"M_AIR_TEMPERATURE - values found:\", unique_values)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "plt.hist(df_weather['M_AIR_TEMPERATURE'],bins=100)\n",
    "plt.xlabel('M_AIR_TEMPERATURE (in $^\\circ$C)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of M_AIR_TEMPERATURE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather[\"M_AIR_TEMPERATURE\"].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3))\n",
    "for weather, group in df_weather.groupby('M_WEATHER_LABEL'):\n",
    "    plt.hist(group['M_AIR_TEMPERATURE'], bins=10, alpha=0.5, label=weather)\n",
    "plt.xlabel('M_AIR_TEMPERATURE ($^\\circ$C)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of M_AIR_TEMPERATURE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate a list of colors (you can choose any colormap here)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(df_weather['M_WEATHER_LABEL'].unique())))\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=len(df_weather['M_WEATHER_LABEL'].unique()), ncols=1, figsize=(5, 3 * len(df_weather['M_WEATHER_LABEL'].unique())))\n",
    "\n",
    "# Flatten axes if there are multiple subplots\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each group in a separate subplot\n",
    "for i, (weather, group) in enumerate(df_weather.groupby('M_WEATHER_LABEL')):\n",
    "    axes[i].hist(group['M_AIR_TEMPERATURE'], bins=10, alpha=0.7, color=colors[i])\n",
    "    axes[i].set_xlabel('M_AIR_TEMPERATURE ($^\\circ$C)')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_title(f'Histogram of M_AIR_TEMPERATURE ({weather})')\n",
    "\n",
    "# Adjust layout for better display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usableai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
