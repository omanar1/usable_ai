{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "listed-sector",
   "metadata": {},
   "source": [
    "# Homework 9 - Parameter Search and Feature Selection\n",
    "In this assignment, you will be working with the cars dataset to perform parameter search and feature selection using various techniques. The goal is to explore the performance of a machine learning model by optimizing its parameters and selecting the most relevant features. We will try to predict the Make of the car based on its attributes.\n",
    "\n",
    "Complete the missing parts in this guide.\n",
    "\n",
    "### Step 1: Load Data\n",
    "You can load the data from the provided CSV file using `pandas`.\n",
    "\n",
    "### Step 2: Preprocess and split data\n",
    "Use attributes `['Make', 'Engine HP', 'Engine Cylinders', 'Number of Doors', 'highway MPG', 'city mpg', 'MSRP']` (x) to predict the `Make` (y, target variable). Note that `Make` is a categorical variable, so you will need to use a classification model.\n",
    " - You should handle missing values appropriately (suggestion: drop rows with missing values).\n",
    " - You should remove Makes that have less than 20 samples.\n",
    " - You should split the data into training and testing sets.\n",
    "\n",
    "### Step 3: Predict Make using a Decision Tree Classifier\n",
    "Use a Decision Tree Classifier to predict the `Make` of the car. You will need to:\n",
    " - Train the model on the training set.\n",
    " - Evaluate the model on the test set using different metrics (use the `report` function from `sklearn.metrics`).\n",
    " - Showcase the confusion matrix to visualize the performance of the model. Do you see any interesting patterns in the confusion matrix?\n",
    "\n",
    "### Step 4: Perform Parameter Search\n",
    "Use `GridSearchCV` to perform a parameter search on the Decision Tree Classifier. You can use `criterion`, `max_depth`, and `splitter` as parameters to search over. Check the documentation for Decistion Tree Classifier to see the available parameters.\n",
    " - Discuss if the model performance improved after the parameter search.\n",
    "\n",
    "### Step 5: Feature Selection\n",
    "Use the best model from the parameter search to perform feature selection. Use `feature_importances_` to get the importance of each feature in the model. You can use `SelectFromModel` from `sklearn.feature_selection` to select the most important features based on the model's feature importances.\n",
    " - You can visualize the feature importances using a bar chart for better understanding.\n",
    " - Discuss which features are most important and how they impact the model's performance.\n",
    " \n",
    "### Step 6: Plot ROC Curve and calculate AUC\n",
    "Use the best model from the parameter search to plot the ROC curve and calculate the AUC (Area Under the Curve) score for one of the classes (e.g., `Toyota`). You can use `roc_curve` and `auc` from `sklearn.metrics` to do this. You can use the method `predict_proba` to get the probabilities for each class.\n",
    "\n",
    "### Step 7: Repeat 3-6 for Logistic Regression, KNeighborsClassifier, RandomForestClassifier, and SVM(SVC).\n",
    " - Compare the performance of the classifiers using the same metrics as before.\n",
    " - Discuss which classifier performed best and why.\n",
    " - Check the documentation or ask for help if you are unsure about the parameters to use for each classifier. For instance, for KNeighborsClassifier, you can search over `n_neighbors` and `weights`.\n",
    "\n",
    "\n",
    "## Dataset Overview\n",
    "The cars dataset contains several attributes of various car models, including their specifications and performance metrics.\n",
    "\n",
    "## Submission Guidelines\n",
    "\n",
    "- Submit your completed notebook as a HTML export, or a PDF file.\n",
    "\n",
    "To export to HTML, if you are on Jupyter, select `File` > `Export Notebook As` > `HTML`.\n",
    "\n",
    "If you are on VSCode, you can use the `Jupyter: Export to HTML` command.\n",
    " - Open the command palette (Ctrl+Shift+P or Cmd+Shift+P on Mac).\n",
    "     - Search for `Jupyter: Export to HTML`.\n",
    "     - Save the HTML file to your computer and submit it via Canvas.\n",
    "\n",
    "Make sure the plots appear in the exported file. If you are using plotly or more complicated interactive plots, make sure to a bitmap backend like 'png'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683beb0",
   "metadata": {},
   "source": [
    "Let's start by loading several libraries that we will need for this assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np      # Added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-ocean",
   "metadata": {},
   "source": [
    "Now we need to import the data. This time we will import the `carfeatures.csv` from the Datasets folder. Make any adjustments to the path as necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/carfeatures.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2983b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cd7ec",
   "metadata": {},
   "source": [
    "We will use only a subset of the columns for this assignment. Let's select them:\n",
    "We want to predict `Make`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a479d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our variables\n",
    "x_features = [\n",
    "'Engine HP',\n",
    "'Engine Cylinders',\n",
    "'Number of Doors',\n",
    "'highway MPG',\n",
    "'city mpg',\n",
    "'MSRP'\n",
    "]\n",
    "\n",
    "# Target variable\n",
    "y_feature = 'Make'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c46878",
   "metadata": {},
   "source": [
    "Next, we need to drop rows with missing values among the selected columns. (You can use `dropna()` method from pandas with a `subset` parameter that restricts the operation to the selected columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b64ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing values in x_features\n",
    "\n",
    "# Combine the feature columns and the target column\n",
    "columns_to_check = x_features + [y_feature]\n",
    "\n",
    "df = df.dropna(subset=columns_to_check) # COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c847d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d0d22",
   "metadata": {},
   "source": [
    "We need to remove rows where the `Make` has not many samples. We can use `value_counts()` to find the counts of each Make. I recommend to plot value counts to visualize the distribution of Makes. Let's see how many samples each `Make` has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the distribution of the y_feature. We want to have classes with at least 20 samples.\n",
    "categories_count = df[y_feature].value_counts() # COMPLETE\n",
    "plt.figure(figsize=(10, 6))\n",
    "categories_count.plot(kind='bar', title=f\"{y_feature} Distribution\")\n",
    "#show horizontal line for 20 \n",
    "plt.axhline(y=20, color='r', linestyle='--')\n",
    "plt.xlabel(y_feature)\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a2cb2",
   "metadata": {},
   "source": [
    "We need to remove any entries from `Make` that have less than 20 samples. One solution is getting the indices of the Makes that have less than 20 samples and then dropping those rows from the DataFrame. You can use `isin()` method to filter the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f70047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove classes with less than 20 samples\n",
    "categories_to_remove = categories_count[categories_count < 20].index.tolist() # COMPLETE\n",
    "\n",
    "print(categories_to_remove)\n",
    "\n",
    "df = df[~df[y_feature].isin(categories_to_remove)] # COMPLETE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673dbd9",
   "metadata": {},
   "source": [
    "Define `X` variables (input) and the `y` variable (target) in terms of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[x_features] # COMPLETE\n",
    "y = df[y_feature] # COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8f2a6",
   "metadata": {},
   "source": [
    "Let's now split the dataset into training and testing sets. Let's use a test_size of 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9abb00f",
   "metadata": {},
   "source": [
    "Let's train a simple DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9067406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "# Decision Tree first\n",
    "dt_classifier = DecisionTreeClassifier() # COMPLETE\n",
    "# Fit the model\n",
    "dt_classifier.fit(X_train, y_train) # COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd736c0",
   "metadata": {},
   "source": [
    "Now let's predict and see the report for the decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred_dt = dt_classifier.predict(X_test) # COMPLETE\n",
    "# Evaluate the Decision Tree model\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(classification_report(y_test, y_pred_dt)) # COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ee30c",
   "metadata": {},
   "source": [
    "Plot the confusion matrix to visualize the performance of the model. You can use `confusion_matrix` from `sklearn.metrics` and `heatmap` from `seaborn` to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5aad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt) # COMPLETE\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap='Blues', xticklabels=dt_classifier.classes_, yticklabels=dt_classifier.classes_)\n",
    "plt.title('Confusion Matrix - Decision Tree Classifier')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683fa6b7",
   "metadata": {},
   "source": [
    "Do you see any interesting patterns in the confusion matrix? Discuss briefly any observations you have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d21f99",
   "metadata": {},
   "source": [
    "**OBSERVATIONS**\n",
    "\n",
    "- The dataset is imbalance... some makers/brand have more observations than others, like \n",
    "- The correct classifications (also known as true positives) are along the diagonal. \n",
    "- There is one case that looked to be frequently misclassified in both directions, GMC <-> Chevrolet.\n",
    "- Chevrolet -> Buick and Buick -> Chevrolet looks to be symetric (same number of misclassifications).\n",
    "- Pontiac <-> Chevrolet looks to another case with similar number of misclassifications in both directions.\n",
    "- KIA <-> Hyundai, but notice that misclassify KIA as Hyundai happend more than Hyundai as KIA.\n",
    "- Bentley and Ferrari look to be the high end car makers that are less likely to end up misclassified.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-dairy",
   "metadata": {},
   "source": [
    "Now let's explore the space of parameters for the Decision Tree Classifier. We will use `GridSearchCV` to perform a parameter search on the Decision Tree Classifier. We will search over `criterion`, `max_depth`, and `splitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter space for Decision Tree Classifier\n",
    "# Grid search will evaluate all combinations of these parameters\n",
    "desicion_tree_params_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50],\n",
    "    'splitter': [\"best\", \"random\"]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation for Decision Tree Classifier\n",
    "grid_search_decision_tree_classifier = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    desicion_tree_params_grid,\n",
    "    cv=10, # 10-fold cross-validation\n",
    "    scoring='f1_macro', # Use F1 score for multiclass classification\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "grid_search_decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree best grid score in cv: \" + str(grid_search_decision_tree_classifier.best_score_))\n",
    "print(\"Decision Tree grid test score: \" + str(grid_search_decision_tree_classifier.score(X_test, y_test)))\n",
    "\n",
    "# DEBUGGING\n",
    "print(\"\\nDecision Tree grid training score: \" + str(grid_search_decision_tree_classifier.score(X_train, y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b0ca4d",
   "metadata": {},
   "source": [
    "We can check the best parameters found by the grid search and the best score achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_best_params = grid_search_decision_tree_classifier.best_params_\n",
    "print(\"Decision Tree best params: \" + str(decision_tree_best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5901da",
   "metadata": {},
   "source": [
    "The `grid_search_decision_tree_classifier` object works as a model. You can fit and transform data using it. Let's fit the model to the training data and then evaluate it on the test set.\n",
    "So let's see how the model performs after the parameter search. We will use the `report` function to evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bdd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_best_params = grid_search_decision_tree_classifier.best_params_\n",
    "print(\"Decision Tree best params: \" + str(decision_tree_best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-norwegian",
   "metadata": {},
   "source": [
    "Now we can run `predict()` on our `grid_search_decision_tree_classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search_decision_tree_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-inquiry",
   "metadata": {},
   "source": [
    "Let's look at the resulting report. Call `classification_report()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-acoustic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search_decision_tree_classification_report = classification_report(y_test, y_pred)\n",
    "print(\"Decision Tree Classification report with test data\")\n",
    "print(grid_search_decision_tree_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a85d12",
   "metadata": {},
   "source": [
    "Now, let's see the feature importances of the Decision Tree Classifier. You can access the `feature_importances_` attribute of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3908715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importances_dt = dt_classifier.feature_importances_ # COMPLETE\n",
    "# Plot feature importances (you can use matplotlib or seaborn)\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': x_features, 'Importance': feature_importances_dt})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', hue='Feature', data=feature_importance_df, palette='viridis', legend=False)\n",
    "plt.title('Feature Importance from Decision Tree Classifier')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-blend",
   "metadata": {},
   "source": [
    "We'll need to grab the features to use now, using the `SelectFromModel()` function. Then, let's run `fit()` on `select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectFromModel(DecisionTreeClassifier(), threshold='median')\n",
    "\n",
    "# which features were selected?\n",
    "print(\"Features before selection:\")\n",
    "print(X_train.columns.tolist())\n",
    "\n",
    "select.fit(X_train, y_train) # Your Code Here\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)\n",
    "\n",
    "# which features were selected?\n",
    "selected_features = X_train.columns[select.get_support()]\n",
    "print(\"\\nSelected features after selection:\")\n",
    "print(selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-remark",
   "metadata": {},
   "source": [
    "Now let's apply those best params froem the grid search. Assign the respective fields from `decision_tree_best_params` for your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying DecisionTreeClassifier using the best params from the grid search and with selected data\n",
    "decision_tree_classifier = DecisionTreeClassifier(**decision_tree_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-advertising",
   "metadata": {},
   "source": [
    "We need to run the `fit()` function using `X_train_selected` and `y_train` as parameters. Then, run `predict()` using `X_test_selected`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-methodology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision_tree_classifier.fit(X_train_selected, y_train) # COMPLETE\n",
    "y_pred_selected = decision_tree_classifier.predict(X_test_selected) # COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d512c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training accuracy DEBUGGING\n",
    "train_accuracy = decision_tree_classifier.score(X_train_selected, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bd9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = X.corr()\n",
    "\n",
    "# Display the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-stuff",
   "metadata": {},
   "source": [
    "Lastly, rerun the `classification_report()` and print out what your results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, rerun the `classification_report()` and print out what your results are.\n",
    "decision_tree_classification_report_selected = classification_report(y_test, y_pred_selected) # COMPLETE\n",
    "print(\"Decision Tree Classification report with selected features\")\n",
    "print(decision_tree_classification_report_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c4f919",
   "metadata": {},
   "source": [
    "**Do you see any improvements?**\n",
    "\n",
    "Not any major improvement. The accuracy of the model decrease from 0.81 → 0.78 is small, about ~3%.\n",
    "\n",
    "So it could suggest:\n",
    "\n",
    "- The features dropped (`Engine Cylinders`, `Number of Doors`, `city mpg`) do not look to be critically important.\n",
    "\n",
    "- A smaller feature set (variables that explain) implies a simpler, faster, more general, and easier model to interpret.\n",
    "\n",
    "- Notice that there features that have high correlation, e.g. `city mpg` and `highway MPG` so by dropping `highway MPG` so we end up with less multicollinearity, hence improving model robustness, and trading-off a small additional information that the extra feature may bring (high correlation between features mean that we have redundant information in a way). A similar case is observed between `Engine HP` and `Engine Cylinders`.\n",
    "\n",
    "Looking at the training accuracy, it dropped a bit (0.99 to 0.98) so a bit of over-fitting went away - but nothing major, I will think. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb6e8d",
   "metadata": {},
   "source": [
    "Finally, let's plot the ROC (Receiver Operating Characteristic) curve to evaluate the performance of our model. Note that we will need to use the `predict_proba()` method to get the probabilities for each class. Feel free to choose one of the classes, for example, `Toyota`. Note that Decision Tree Classifier is not the best for ROC curves as they are not probabilistic models, but we can still plot it for the sake of this exercise. The ROC curves for the other classifiers will be more meaningful.\n",
    "\n",
    "Plot the ROC with a line for the random classifier (diagonal line) and the ROC curve for the Decision Tree Classifier. Calculate the area under the curve (AUC). You can use `roc_curve` and `auc` from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff055d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = grid_search_decision_tree_classifier.predict_proba(X_test)\n",
    "chosenClass = \"Toyota\"\n",
    "chosenClassIndex = grid_search_decision_tree_classifier.classes_.tolist().index(chosenClass)\n",
    "fpr, tpr, _ = roc_curve(y_test == chosenClass, y_score[:, chosenClassIndex])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "# Plot ROC curves: tpr vs fpr (x-axis is fpr, y-axis is tpr)\n",
    "# Don't forget to draw the random guess line (y=x) use dash line \n",
    "\n",
    "# YOUR CODE HERE\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'Decision Tree (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random Classifier')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title(f'ROC Curve - Decision Tree Classifier for \"{chosenClass}\"')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30733e61",
   "metadata": {},
   "source": [
    "### Now let's repeat the steps 3-6 for Logistic Regression, KNeighborsClassifier, RandomForestClassifier, and SVM (SVC).\n",
    "\n",
    "For Logistic Regression and SVM we recommend using standardized X features. You can use `StandardScaler` from `sklearn.preprocessing` to standardize the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47370fb",
   "metadata": {},
   "source": [
    "For instance, let's prepare the data for Logistic Regression and SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbe1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression works best if the data is scaled, so we will scale the data using StandardScaler.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be703c7a",
   "metadata": {},
   "source": [
    "Now similarly perform the above operations for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "lr= LogisticRegression(C=1000.0, random_state=42,max_iter=1000) #Your Code Here\n",
    "# Using settings from HW 7\n",
    "\n",
    "lr.fit(X_train_scaled, y_train.to_numpy())  # .ravel() will be deprecated\n",
    "y_pred= lr.predict(X_test_scaled)\n",
    "\n",
    "print(f'Accuracy Logistic Regression: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classification_report = classification_report(y_test, y_pred, zero_division=np.nan)\n",
    "print(\"Logistic Regression Classification report\")\n",
    "print(decision_tree_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b64fc",
   "metadata": {},
   "source": [
    "Now similarly perform the above operations for KNeighborsClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Using one neighbor \n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean') # Your Code here\n",
    "\n",
    "#Your Code to fit the model here\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_scaled) # Your Prediction Code Here\n",
    "\n",
    "# Your Accuracy Output Code Here\n",
    "print(f'Accuracy KNN: {accuracy_score(y_test, y_pred_knn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c59b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_decision_tree_classification_report = classification_report(y_test, y_pred_knn, zero_division=np.nan)\n",
    "print(\"KNN Classification report\")\n",
    "print(knn_decision_tree_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906b5ba",
   "metadata": {},
   "source": [
    "Now similarly perform the above operations for Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "# Using some default for random forest\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = model.predict(X_test_scaled)\n",
    "print(f'Accuracy Random Forest: {accuracy_score(y_test, y_pred_rf):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a21425",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_decision_tree_classification_report = classification_report(y_test, y_pred_rf, zero_division=np.nan)\n",
    "print(\"Random Forest Classification report\")\n",
    "print(RF_decision_tree_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89c711",
   "metadata": {},
   "source": [
    "Now similarly perform the above operations for SVM (SVC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb456ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Using RBF as it looks to work better than linear kernel\n",
    "\n",
    "svm = SVC(kernel='rbf') # Your Code Here\n",
    "    # kernel='linear', C=1.0, random_state=0, cache_size=7000\n",
    "\n",
    "svm.fit(X_train_scaled, y_train.to_numpy())     # ravel() will be deprecated\n",
    "y_pred_svm = svm.predict(X_test_scaled) # Your Prediction Code Here\n",
    "\n",
    "print(f'Accuracy Support Vector Machine with a Radial Basis Function (RBF) kernel: {accuracy_score(y_test, y_pred_svm)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c526ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0127ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_decision_tree_classification_report = classification_report(y_test, y_pred_svm, zero_division=np.nan)\n",
    "print(\"SVM Classification report\")\n",
    "print(svm_decision_tree_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68cb2d3",
   "metadata": {},
   "source": [
    "Based on all the classification reports, which classifier performed best? Discuss the performance of each classifier and the impact of feature selection and parameter tuning on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ef68c",
   "metadata": {},
   "source": [
    "**YOUR DISCUSSION HERE**\n",
    "\n",
    "#### **Summary Table** ####\n",
    "\n",
    "|Accuracy| Result|\n",
    "|---|:---:|\n",
    "|Logistic Regression|0.20770756588268632\n",
    "|KNN| 0.8231793709266081\n",
    "|Random Forest| 0.8461\n",
    "|Support Vector Machine with<br/> a Radial Basis Function (RBF) kernel| 0.30036837631056956\n",
    "\n",
    "**Random Forest** is a powerful ensemble method that typically handles noise, irrelevant features, and non-linear data very well. It benefits from aggregating many decision trees, which reduces overfitting and improves generalization, likely explaining its better performance in comparison to the other models.\n",
    "\n",
    "<br/>\n",
    "\n",
    "**KNN** is a simple yet effective method when the data has clear class boundaries. Its good performance suggests that the features selected offer good clustering/separation between classes. Also, the Scaling was a factor that benefited KNN model.\n",
    "\n",
    "Interesting to observe that there are some makers where KNN is outperforming Random Forest (Aston Martin is the more evident), like: \n",
    "\n",
    "|Make|Random Forest Classification|||KNN Classification|||\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|  |precision (RF)|\trecall (RF)|\tf1-score (RF)|\tprecision (KNN)|\trecall (KNN)|\tf1-score (KNN)|\n",
    "|Aston Martin|0.79|\t0.95|\t0.86|\t1|\t1|\t1|\n",
    "|Ferrari   | 0.96|\t1|\t0.98|\t1|\t1|\t1|\n",
    "|Land Rover| 0.92|\t0.9|\t0.91|\t0.95|\t0.92|\t0.94|\n",
    "|Lexus     | 0.76|0.85|\t0.81|\t0.81|\t0.84|\t0.82|\n",
    "|Lotus     | 0.9|1|\t0.95|\t1|\t1|\t1|\n",
    "|Maserati  | 1  |0.91\t|0.95\t|0.96\t|0.96\t|0.96|\n",
    "|Pontiac   |0.68|\t0.57|\t0.62|\t0.7|\t0.62|\t0.66|\n",
    "\n",
    "\n",
    "For the following makers, the have pretty much the same result.\n",
    "\n",
    "|Make|Random Forest Classification|||KNN Classification|||\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|  |precision (RF)|\trecall (RF)|\tf1-score (RF)|\tprecision (KNN)|\trecall (KNN)|\tf1-score (KNN)|\n",
    "|Cadillac|\t0.9|\t0.94|\t0.92|\t0.91|\t0.92|\t0.92|\n",
    "|FIAT\t|0.89\t|0.94\t|0.92\t|0.89\t|0.94\t|0.92|\n",
    "|Lamborghini|\t0.94\t|1\t|0.97\t|0.94\t|1\t|0.97|\n",
    "|Rolls-Royce|\t1\t|0.82\t|0.9\t|1\t|0.82\t|0.9|\n",
    "\n",
    "<br/>\n",
    "\n",
    "**SVM with RBF Kernel** usually does well on non-linear problems, but its poor performance suggests that the parameters (like C, gamma) were not well tuned.\n",
    "\n",
    "If we play with the `C` and `gamma` parameters then we can find a better model:\n",
    "\n",
    "|Tuned Support Vector Machine|Accuracy |\n",
    "|---|---|\n",
    "|Using Radial Basis Function (RBF) kernel<br/>using `C` = 10, `gamma` = 1|0.6225559648625673|\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Logistic Regression** works best when the decision boundary between classes is linear. Its low accuracy suggests that the data has complex, non-linear relationships that Logistic Regression couldn't capture. The Scaling helped the model but not enough. In comparison, the other models looked to be handling better the non-linearity.\n",
    "\n",
    "Logistic Regression shows recall zero for 8 Makers (Acura,FIAT,Hyundai,Infiniti,Kia,Lincoln,Mitsubishi,Scion), it fails to identify any of the positive instances for any of these makers.\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Final Remarks**\n",
    "\n",
    "Considering how simple KNN works and it can be explained then it it is remarkable that it accomplished in comparison to the best one (Random Forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different parameters for SVM \n",
    "\n",
    "for parameter_C in [1, 10]:\n",
    "    for parameter_gamma in [1, 0.1]:\n",
    "\n",
    "        svm = SVC(kernel='rbf', C=parameter_C, gamma=parameter_gamma) # Your Code Here\n",
    "\n",
    "        svm.fit(X_train_scaled, y_train.to_numpy())     # ravel() will be deprecated\n",
    "        y_pred_svm = svm.predict(X_test_scaled) # Your Prediction Code Here\n",
    "\n",
    "        print(f'\\nParameter C: {parameter_C} | Parameter Gamma: {parameter_gamma}')\n",
    "        print(f'Accuracy Support Vector Machine with a Radial Basis Function (RBF) kernel: {accuracy_score(y_test, y_pred_svm)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using better settings for SVM\n",
    "\n",
    "parameter_C = 10\n",
    "parameter_gamma = 1\n",
    "\n",
    "svm = SVC(kernel='rbf', C=parameter_C, gamma=parameter_gamma) # Your Code Here\n",
    "\n",
    "svm.fit(X_train_scaled, y_train.to_numpy())     # ravel() will be deprecated\n",
    "y_pred_svm = svm.predict(X_test_scaled) # Your Prediction Code Here\n",
    "\n",
    "print(f'\\nParameter C: {parameter_C} | Parameter Gamma: {parameter_gamma}')\n",
    "print(f'Accuracy Support Vector Machine with a Radial Basis Function (RBF) kernel: {accuracy_score(y_test, y_pred_svm)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_svm_decision_tree_classification_report = classification_report(y_test, y_pred_svm, zero_division=np.nan)\n",
    "print(\"SVM Classification report (gamma=1, C=10)\")\n",
    "print(tunned_svm_decision_tree_classification_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
